name: Generate Super RSS Feed

on:
  schedule:
    # Run 3 times daily for cumulative feed updates
    - cron: '0 14 * * *'  # 6:00 AM Pacific (14:00 UTC)
    - cron: '0 22 * * *'  # 2:00 PM Pacific (22:00 UTC)
    - cron: '0 6 * * *'   # 10:00 PM Pacific (06:00 UTC next day)
  workflow_dispatch:  # Allow manual trigger

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Download existing feeds from GitHub Pages
        run: |
          echo "Downloading existing feeds from gh-pages..."
          for feed in local ai-tech climate homelab news science scifi; do
            wget -q "https://zirnhelt.github.io/super-rss-feed/feed-${feed}.json" -O "feed-${feed}.json" || echo "No existing feed-${feed}.json"
          done
          # Download themed podcast feeds
          for day in monday tuesday wednesday thursday friday saturday sunday; do
            wget -q "https://zirnhelt.github.io/super-rss-feed/feed-podcast-${day}.json" -O "feed-podcast-${day}.json" || echo "No existing feed-podcast-${day}.json"
          done
          # Download podcast cache
          wget -q "https://zirnhelt.github.io/super-rss-feed/podcast_articles_cache.json" -O "podcast_articles_cache.json" || echo "No existing podcast_articles_cache.json"
          echo "Download complete. Feed sizes:"
          wc -l feed-*.json
        continue-on-error: true
      
      - name: Generate RSS feed
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          python super_rss_curator_json.py feeds.opml
      
      - name: Copy files to output
        run: |
          echo "Files in current directory:"
          ls -la
          mkdir -p output

          # Copy all category feeds and podcast feeds
          cp feed-*.json output/

          # Copy website files
          cp index.html output/
          cp curated-feeds.opml output/

          # Copy cache files (for persistence between runs)
          cp scored_articles_cache.json output/
          cp shown_articles_cache.json output/
          cp wlt_cache.json output/
          cp podcast_articles_cache.json output/

          echo "Files in output directory:"
          ls -la output/

      - name: Commit cache files
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add scored_articles_cache.json wlt_cache.json shown_articles_cache.json podcast_articles_cache.json
          git diff --quiet && git diff --staged --quiet || git commit -m "Update cache files [skip ci]"
          git push
      
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./output
          publish_branch: gh-pages
          keep_files: false
          commit_message: 'Update RSS feed'
